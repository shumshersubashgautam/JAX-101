{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0nDklWmZ0jPR"
      },
      "outputs": [],
      "source": [
        "# @title Install required packages (run me) { display-mode: \"form\" }\n",
        "# This may take a minute or two to complete.\n",
        "%%capture\n",
        "!pip install jaxlib\n",
        "!pip install jax\n",
        "!pip install git+https://github.com/deepmind/dm-haiku\n",
        "!pip install gym==0.25\n",
        "!pip install gym[box2d]\n",
        "!pip install optax\n",
        "!pip install matplotlib\n",
        "!pip install chex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import required packages (run me) { display-mode: \"form\" }\n",
        "%%capture\n",
        "import copy\n",
        "from shutil import rmtree # deleting directories\n",
        "import random\n",
        "import collections # useful data structures\n",
        "import numpy as np\n",
        "import gym # reinforcement learning environments\n",
        "from gym.wrappers import RecordVideo\n",
        "import jax\n",
        "import jax.numpy as jnp # jax numpy\n",
        "import haiku as hk # jax neural network library\n",
        "import optax # jax optimizer library\n",
        "import matplotlib.pyplot as plt # graph plotting library\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import chex\n",
        "\n",
        "# Hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "DbGnHBgi1Nu6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "env_name = \"CartPole-v0\"\n",
        "env = gym.make(env_name)"
      ],
      "metadata": {
        "id": "NsraxG0-2QzH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the environment\n",
        "s_0 = env.reset()\n",
        "print(\"Initial State::\", s_0)\n",
        "\n",
        "# Get environment obs space\n",
        "obs_shape = env.observation_space.shape\n",
        "print(\"Environment Obs Space Shape:\", obs_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw1Yjy7i2tfD",
        "outputId": "caaa2e4e-82e5-42af-a6f1-840ee2b0cf1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State:: [ 0.04090678 -0.02435194  0.04944371 -0.03584683]\n",
            "Environment Obs Space Shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get action space - e.g. discrete or continuous\n",
        "print(f\"Environment action space: {env.action_space}\")\n",
        "\n",
        "# Get num actions\n",
        "num_actions = env.action_space.n\n",
        "print(f\"Number of actions: {num_actions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dowXiU6P2v7z",
        "outputId": "c726ef58-2b0a-4164-9d73-789deeebd0d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment action space: Discrete(2)\n",
            "Number of actions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Solution exercise 1 { display-mode: \"form\" }\n",
        "\n",
        "def linear_policy(params, obs):\n",
        "  \"\"\"A simple linear policy\n",
        "\n",
        "  Args:\n",
        "    params: a vector of four real-numbers that give the parameters of the policy\n",
        "    obs: a vector of four real-numbers that give the agent's observation\n",
        "\n",
        "  Returns:\n",
        "    a discrete action given by a 0 or 1\n",
        "  \"\"\"\n",
        "  # YOUR CODE\n",
        "  dot_product_result = jax.numpy.dot(params, obs)\n",
        "\n",
        "  action = jax.lax.select(\n",
        "      dot_product_result > 0, # boolean statement goes here\n",
        "      1, # result when the statement is True goes here\n",
        "      0, # result when the statement is False goes here\n",
        "  )\n",
        "  # END YOUR CODE\n",
        "  return action"
      ],
      "metadata": {
        "id": "vf6fFoUS21Oj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check exercise 1 (run me) { display-mode: \"form\" }\n",
        "\n",
        "def check_linear_policy(linear_policy):\n",
        "  fixed_obs = jnp.array([1,1,2,4])\n",
        "\n",
        "  # check case1 - negative dot product.\n",
        "  # weights\n",
        "  params1 = jnp.array([1,1,1,1])\n",
        "  params2 = jnp.array([-1,-1,-1,-1])\n",
        "\n",
        "  hint1 = f\"Incorrect answer, your linear policy is incorrect. The action when \\\n",
        "  obs={fixed_obs} and params={params1} should be 1\"\n",
        "\n",
        "  hint2 = f\"Incorrect answer, your linear policy is incorrect. The action when \\\n",
        "  obs={fixed_obs} and params={params2} should be 0\"\n",
        "\n",
        "  hint = None\n",
        "  if linear_policy(params1, fixed_obs) != 1:\n",
        "    hint = hint1\n",
        "  elif linear_policy(params2, fixed_obs) != 0:\n",
        "    hint = hint2\n",
        "\n",
        "  if hint is not None:\n",
        "    print(hint)\n",
        "  else:\n",
        "    print(\"Your function is correct!\")\n",
        "\n",
        "try:\n",
        "  check_linear_policy(linear_policy)\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MId5xUxZ26Do",
        "outputId": "0cdbdd2f-5152-4ba8-914f-52da466e2eb8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your function is correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the initial obs by resetting the env\n",
        "initial_obs = env.reset()\n",
        "\n",
        "# Randomly sample actions from env\n",
        "action = env.action_space.sample()\n",
        "\n",
        "# Step the environment\n",
        "next_obs, reward, done, info = env.step(action)\n",
        "\n",
        "print(\"Observation:\", initial_obs)\n",
        "print(\"Action:\", action)\n",
        "print(\"Next observation:\", next_obs)\n",
        "print(\"Reward:\", reward)\n",
        "print(\"Game is done:\", done)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKccGhI43c0M",
        "outputId": "f865150b-58f7-4dba-9f63-5f409ce93b37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation: [-0.03103711  0.02935717 -0.02909264 -0.00151746]\n",
            "Action: 0\n",
            "Next observation: [-0.03044996 -0.16533573 -0.02912299  0.28184628]\n",
            "Reward: 1.0\n",
            "Game is done: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(env):\n",
        "  episode_return = 0 # counter to keep track of rewards\n",
        "  done = False # initially set to False\n",
        "  params = jnp.array([1,-2,2,-1]) # fixed policy parameters\n",
        "\n",
        "  ## YOUR CODE\n",
        "\n",
        "  obs = env.reset() # TODO: get the initial obs from the env\n",
        "\n",
        "\n",
        "  while not done: # loop until episode is done\n",
        "\n",
        "    action = linear_policy(params, obs) # TODO: compute action using linear policy\n",
        "    action = np.array(action) # We need to the convert the action from the policy to a np.array\n",
        "\n",
        "    obs, reward, done, info = env.step(action) # TODO: step the environment\n",
        "\n",
        "\n",
        "    episode_return = episode_return + reward # TODO: add reward to episode return\n",
        "\n",
        "  return episode_return"
      ],
      "metadata": {
        "id": "8dCn07AO3h0m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title Soluction Exercise 2 { display-mode: \"form\" }\n",
        "# def run_episode(env):\n",
        "#   episode_return = 0 # counter to keep track of rewards\n",
        "#   done = False # initially set to False\n",
        "#   params = jnp.array([1,-2,2,-1]) # fixed policy parameters\n",
        "\n",
        "#   ## YOUR CODE\n",
        "\n",
        "#   obs = env.reset() # TODO: get the initial obs from the env\n",
        "\n",
        "#   while not done: # loop until episode is done\n",
        "\n",
        "#     # HINT: You might need to the convert the action from your policy to a np.array\n",
        "#     action = linear_policy(params, obs) # TODO: compute action using linear policy\n",
        "#     action = np.array(action) # We need to the convert the action from the policy to a np.array\n",
        "\n",
        "#     obs, reward, done, info = env.step(action) # TODO: step the environment\n",
        "\n",
        "#     episode_return = episode_return + reward # TODO: add reward to episode return\n",
        "\n",
        "#   return episode_return"
      ],
      "metadata": {
        "id": "euHUizeo31Nl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check exercise 2 (run me) { display-mode: \"form\" }\n",
        "\n",
        "try:\n",
        "  env.seed(42)\n",
        "  if run_episode(env) == 31:\n",
        "    print(\"Looks correct!\")\n",
        "  else:\n",
        "    print(\"Looks like your implementation might be wrong.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUweOcHO3xMd",
        "outputId": "2c00d42d-bc75-40eb-b56b-61260455cab6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop (run me) { display-mode: \"form\" }\n",
        "\n",
        "# NamedTuple to store transitions\n",
        "Transition = collections.namedtuple(\"Transition\", [\"obs\", \"action\", \"reward\", \"next_obs\", \"done\"])\n",
        "\n",
        "# Training Loop\n",
        "def run_training_loop(env_name, agent_params, agent_select_action_func,\n",
        "    agent_actor_state=None, agent_learn_func=None, agent_learner_state=None,\n",
        "    agent_memory=None, num_episodes=1000, evaluator_period=100,\n",
        "    evaluation_episodes=8, learn_steps_per_episode=1,\n",
        "    train_every_timestep=False, video_subdir=\"\",):\n",
        "    \"\"\"\n",
        "    This function runs several episodes in an environment and periodically does\n",
        "    some agent learning and evaluation.\n",
        "\n",
        "    Args:\n",
        "        env: a gym environment.\n",
        "        agent_params: an object to store parameters that the agent uses.\n",
        "        agent_select_func: a function that does action selection for the agent.\n",
        "        agent_actor_state (optional): an object that stores the internal state\n",
        "            of the agents action selection function.\n",
        "        agent_learn_func (optional): a function that does some learning for the\n",
        "            agent by updating the agent parameters.\n",
        "        agent_learn_state (optional): an object that stores the internal state\n",
        "            of the agent learn function.\n",
        "        agent_memory (optional): an object for storing an retrieving historical\n",
        "            experience.\n",
        "        num_episodes: how many episodes to run.\n",
        "        evaluator_period: how often to run evaluation.\n",
        "        evaluation_episodes: how many evaluation episodes to run.\n",
        "        train_every_timestep: whether to train every timestep rather than at the end\n",
        "            of the episode.\n",
        "        video_subdir: subdirectory to store epsiode recordings.\n",
        "\n",
        "    Returns:\n",
        "        episode_returns: list of all the episode returns.\n",
        "        evaluator_episode_returns: list of all the evaluator episode returns.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup Cartpole environment and recorder\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\") # training environment\n",
        "    eval_env = gym.make(env_name, render_mode=\"rgb_array\") # evaluation environment\n",
        "\n",
        "    # Video dir\n",
        "    video_dir = \"./video\"+\"/\"+video_subdir\n",
        "\n",
        "    # Clear video dir\n",
        "    try:\n",
        "      rmtree(video_dir)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # Wrap in recorder\n",
        "    env = RecordVideo(env, video_dir+\"/train\", episode_trigger=lambda x: (x % evaluator_period) == 0)\n",
        "    eval_env = RecordVideo(eval_env, video_dir+\"/eval\", episode_trigger=lambda x: (x % evaluation_episodes) == 0)\n",
        "\n",
        "    # JAX random number generator\n",
        "    rng = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
        "    env.seed(0) # seed environment for reproducability\n",
        "    random.seed(0)\n",
        "\n",
        "    episode_returns = [] # List to store history of episode returns.\n",
        "    evaluator_episode_returns = [] # List to store history of evaluator returns.\n",
        "    timesteps = 0\n",
        "    for episode in range(num_episodes):\n",
        "\n",
        "        # Reset environment.\n",
        "        obs = env.reset()\n",
        "        episode_return = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "\n",
        "            # Agent select action.\n",
        "            action, agent_actor_state = agent_select_action_func(\n",
        "                                            next(rng),\n",
        "                                            agent_params,\n",
        "                                            agent_actor_state,\n",
        "                                            np.array(obs)\n",
        "                                        )\n",
        "\n",
        "            # Step environment.\n",
        "            next_obs, reward, done, _ = env.step(int(action))\n",
        "\n",
        "            # Pack into transition.\n",
        "            transition = Transition(obs, action, reward, next_obs, done)\n",
        "\n",
        "            # Add transition to memory.\n",
        "            if agent_memory: # check if agent has memory\n",
        "              agent_memory.push(transition)\n",
        "\n",
        "            # Add reward to episode return.\n",
        "            episode_return += reward\n",
        "\n",
        "            # Set obs to next obs before next environment step. CRITICAL!!!\n",
        "            obs = next_obs\n",
        "\n",
        "            # Increment timestep counter\n",
        "            timesteps += 1\n",
        "\n",
        "            # Maybe learn every timestep\n",
        "            if train_every_timestep and (timesteps % 4 == 0) and agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )\n",
        "\n",
        "        episode_returns.append(episode_return)\n",
        "\n",
        "        # At the end of every episode we do a learn step.\n",
        "        if agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "\n",
        "            for _ in range(learn_steps_per_episode):\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )\n",
        "\n",
        "        if (episode % evaluator_period) == 0: # Do evaluation\n",
        "\n",
        "            evaluator_episode_return = 0\n",
        "            for eval_episode in range(evaluation_episodes):\n",
        "                obs = eval_env.reset()\n",
        "                done = False\n",
        "                while not done:\n",
        "                    action, _ = agent_select_action_func(\n",
        "                                    next(rng),\n",
        "                                    agent_params,\n",
        "                                    agent_actor_state,\n",
        "                                    np.array(obs),\n",
        "                                    evaluation=True\n",
        "                                )\n",
        "\n",
        "                    obs, reward, done, _ = eval_env.step(int(action))\n",
        "\n",
        "                    evaluator_episode_return += reward\n",
        "\n",
        "            evaluator_episode_return /= evaluation_episodes\n",
        "\n",
        "            evaluator_episode_returns.append(evaluator_episode_return)\n",
        "\n",
        "            logs = [\n",
        "                    f\"Episode: {episode}\",\n",
        "                    f\"Episode Return: {episode_return}\",\n",
        "                    f\"Average Episode Return: {np.mean(episode_returns[-20:])}\",\n",
        "                    f\"Evaluator Episode Return: {evaluator_episode_return}\"\n",
        "            ]\n",
        "\n",
        "            print(*logs, sep=\"\\t\") # Print the logs\n",
        "\n",
        "    env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return episode_returns, evaluator_episode_returns"
      ],
      "metadata": {
        "id": "W0xdmPuE4RRS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Soluction Exercise 2 { display-mode: \"form\" }\n",
        "def run_episode(env):\n",
        "  episode_return = 0 # counter to keep track of rewards\n",
        "  done = False # initially set to False\n",
        "  params = jnp.array([1,-2,2,-1]) # fixed policy parameters\n",
        "\n",
        "  ## YOUR CODE\n",
        "\n",
        "  obs = env.reset() # TODO: get the initial obs from the env\n",
        "\n",
        "  while not done: # loop until episode is done\n",
        "\n",
        "    # HINT: You might need to the convert the action from your policy to a np.array\n",
        "    action = linear_policy(params, obs) # TODO: compute action using linear policy\n",
        "    action = np.array(action) # We need to the convert the action from the policy to a np.array\n",
        "\n",
        "    obs, reward, done, info = env.step(action) # TODO: step the environment\n",
        "\n",
        "    episode_return = episode_return + reward # TODO: add reward to episode return\n",
        "\n",
        "  return episode_return"
      ],
      "metadata": {
        "id": "nzioTM6v4era"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check exercise 2 (run me) { display-mode: \"form\" }\n",
        "\n",
        "try:\n",
        "  env.seed(42)\n",
        "  if run_episode(env) == 31:\n",
        "    print(\"Looks correct!\")\n",
        "  else:\n",
        "    print(\"Looks like your implementation might be wrong.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmd1puPx5bpm",
        "outputId": "7cafb91e-16bb-48cb-f823-d357dee0e7e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A General Purpose RL Training Loop**"
      ],
      "metadata": {
        "id": "964fss1s5lmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop (run me) { display-mode: \"form\" }\n",
        "\n",
        "# NamedTuple to store transitions\n",
        "Transition = collections.namedtuple(\"Transition\", [\"obs\", \"action\", \"reward\", \"next_obs\", \"done\"])\n",
        "\n",
        "# Training Loop\n",
        "def run_training_loop(env_name, agent_params, agent_select_action_func,\n",
        "    agent_actor_state=None, agent_learn_func=None, agent_learner_state=None,\n",
        "    agent_memory=None, num_episodes=1000, evaluator_period=100,\n",
        "    evaluation_episodes=8, learn_steps_per_episode=1,\n",
        "    train_every_timestep=False, video_subdir=\"\",):\n",
        "    \"\"\"\n",
        "    This function runs several episodes in an environment and periodically does\n",
        "    some agent learning and evaluation.\n",
        "\n",
        "    Args:\n",
        "        env: a gym environment.\n",
        "        agent_params: an object to store parameters that the agent uses.\n",
        "        agent_select_func: a function that does action selection for the agent.\n",
        "        agent_actor_state (optional): an object that stores the internal state\n",
        "            of the agents action selection function.\n",
        "        agent_learn_func (optional): a function that does some learning for the\n",
        "            agent by updating the agent parameters.\n",
        "        agent_learn_state (optional): an object that stores the internal state\n",
        "            of the agent learn function.\n",
        "        agent_memory (optional): an object for storing an retrieving historical\n",
        "            experience.\n",
        "        num_episodes: how many episodes to run.\n",
        "        evaluator_period: how often to run evaluation.\n",
        "        evaluation_episodes: how many evaluation episodes to run.\n",
        "        train_every_timestep: whether to train every timestep rather than at the end\n",
        "            of the episode.\n",
        "        video_subdir: subdirectory to store epsiode recordings.\n",
        "\n",
        "    Returns:\n",
        "        episode_returns: list of all the episode returns.\n",
        "        evaluator_episode_returns: list of all the evaluator episode returns.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup Cartpole environment and recorder\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\") # training environment\n",
        "    eval_env = gym.make(env_name, render_mode=\"rgb_array\") # evaluation environment\n",
        "\n",
        "    # Video dir\n",
        "    video_dir = \"./video\"+\"/\"+video_subdir\n",
        "\n",
        "    # Clear video dir\n",
        "    try:\n",
        "      rmtree(video_dir)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # Wrap in recorder\n",
        "    env = RecordVideo(env, video_dir+\"/train\", episode_trigger=lambda x: (x % evaluator_period) == 0)\n",
        "    eval_env = RecordVideo(eval_env, video_dir+\"/eval\", episode_trigger=lambda x: (x % evaluation_episodes) == 0)\n",
        "\n",
        "    # JAX random number generator\n",
        "    rng = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
        "    env.seed(0) # seed environment for reproducability\n",
        "    random.seed(0)\n",
        "\n",
        "    episode_returns = [] # List to store history of episode returns.\n",
        "    evaluator_episode_returns = [] # List to store history of evaluator returns.\n",
        "    timesteps = 0\n",
        "    for episode in range(num_episodes):\n",
        "\n",
        "        # Reset environment.\n",
        "        obs = env.reset()\n",
        "        episode_return = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "\n",
        "            # Agent select action.\n",
        "            action, agent_actor_state = agent_select_action_func(\n",
        "                                            next(rng),\n",
        "                                            agent_params,\n",
        "                                            agent_actor_state,\n",
        "                                            np.array(obs)\n",
        "                                        )\n",
        "\n",
        "            # Step environment.\n",
        "            next_obs, reward, done, _ = env.step(int(action))\n",
        "\n",
        "            # Pack into transition.\n",
        "            transition = Transition(obs, action, reward, next_obs, done)\n",
        "\n",
        "            # Add transition to memory.\n",
        "            if agent_memory: # check if agent has memory\n",
        "              agent_memory.push(transition)\n",
        "\n",
        "            # Add reward to episode return.\n",
        "            episode_return += reward\n",
        "\n",
        "            # Set obs to next obs before next environment step. CRITICAL!!!\n",
        "            obs = next_obs\n",
        "\n",
        "            # Increment timestep counter\n",
        "            timesteps += 1\n",
        "\n",
        "            # Maybe learn every timestep\n",
        "            if train_every_timestep and (timesteps % 4 == 0) and agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )\n",
        "\n",
        "        episode_returns.append(episode_return)\n",
        "\n",
        "        # At the end of every episode we do a learn step.\n",
        "        if agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "\n",
        "            for _ in range(learn_steps_per_episode):\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )\n",
        "\n",
        "        if (episode % evaluator_period) == 0: # Do evaluation\n",
        "\n",
        "            evaluator_episode_return = 0\n",
        "            for eval_episode in range(evaluation_episodes):\n",
        "                obs = eval_env.reset()\n",
        "                done = False\n",
        "                while not done:\n",
        "                    action, _ = agent_select_action_func(\n",
        "                                    next(rng),\n",
        "                                    agent_params,\n",
        "                                    agent_actor_state,\n",
        "                                    np.array(obs),\n",
        "                                    evaluation=True\n",
        "                                )\n",
        "\n",
        "                    obs, reward, done, _ = eval_env.step(int(action))\n",
        "\n",
        "                    evaluator_episode_return += reward\n",
        "\n",
        "            evaluator_episode_return /= evaluation_episodes\n",
        "\n",
        "            evaluator_episode_returns.append(evaluator_episode_return)\n",
        "\n",
        "            logs = [\n",
        "                    f\"Episode: {episode}\",\n",
        "                    f\"Episode Return: {episode_return}\",\n",
        "                    f\"Average Episode Return: {np.mean(episode_returns[-20:])}\",\n",
        "                    f\"Evaluator Episode Return: {evaluator_episode_return}\"\n",
        "            ]\n",
        "\n",
        "            print(*logs, sep=\"\\t\") # Print the logs\n",
        "\n",
        "    env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return episode_returns, evaluator_episode_returns"
      ],
      "metadata": {
        "id": "34jAD8s25f3t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter container for Random Policy Search\n",
        "RandomPolicySearchParams = collections.namedtuple(\"RandomPolicySearchParams\", [\"current\", \"best\"])\n",
        "\n",
        "# TEST: store two different sets of parameters\n",
        "current_params = np.ones(obs_shape) * -1\n",
        "best_params = np.zeros(obs_shape)\n",
        "rps_params = RandomPolicySearchParams(current_params, best_params)\n",
        "\n",
        "# How to access the best or current params.\n",
        "print(f\"Best params: {rps_params.best}\")\n",
        "print(f\"Current params: {rps_params.current}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQjSeZ-b5rx3",
        "outputId": "27f2148e-af64-4ef5-caf5-c4fa790fb125"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: [0. 0. 0. 0.]\n",
            "Current params: [-1. -1. -1. -1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution exercise 3 {display-mode: \"form\"}\n",
        "\n",
        "def random_policy_search_choose_action(\n",
        "    key,\n",
        "    params,\n",
        "    actor_state,\n",
        "    obs,\n",
        "    evaluation=False\n",
        "):\n",
        "\n",
        "  best_action = linear_policy(params.best, obs)\n",
        "\n",
        "  current_action = linear_policy(params.current, obs)\n",
        "\n",
        "  action = jax.lax.select(\n",
        "      evaluation ,\n",
        "      best_action ,\n",
        "      current_action\n",
        "  )\n",
        "\n",
        "  return action, actor_state"
      ],
      "metadata": {
        "id": "5bSLM5Cs54Zn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check exercise 3 (run me) {display-mode: \"form\"}\n",
        "\n",
        "def check_random_policy_search_choose_action(choose_action):\n",
        "  key = None # not used\n",
        "  actor_state = None # not used\n",
        "\n",
        "  # obs\n",
        "  obs = np.ones(obs_shape)\n",
        "\n",
        "  evaluation=False\n",
        "  current_params = np.ones(obs_shape) * -1\n",
        "  best_params = np.ones(obs_shape)\n",
        "  rps_params = RandomPolicySearchParams(current_params, best_params)\n",
        "  action, actor_state = choose_action(key,rps_params,actor_state,obs,evaluation)\n",
        "  if action != 0:\n",
        "    return False\n",
        "\n",
        "  evaluation=True\n",
        "  current_params = np.ones(obs_shape) * -1\n",
        "  best_params = np.ones(obs_shape)\n",
        "  rps_params = RandomPolicySearchParams(current_params, best_params)\n",
        "  action, actor_state = choose_action(key,rps_params,actor_state,obs,evaluation)\n",
        "  if action != 1:\n",
        "    return False\n",
        "\n",
        "  return True\n",
        "\n",
        "try:\n",
        "  if check_random_policy_search_choose_action(random_policy_search_choose_action):\n",
        "    print(\"Your function looks correct.\")\n",
        "  else:\n",
        "    print(\"Your function looks incorrect.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ-nxR-x5-VX",
        "outputId": "b1f005eb-cef4-49e9-ee42-827099f7446d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your function looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RPS agent memory**"
      ],
      "metadata": {
        "id": "xZYHLFbT6Hd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Average Episode Return Memory**"
      ],
      "metadata": {
        "id": "DaV7fDzw6NS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageEpisodeReturnBuffer:\n",
        "\n",
        "    def __init__(self, num_episodes_to_store=50):\n",
        "        \"\"\"\n",
        "        This class implements an agent memory that stores the average episode\n",
        "        return over the last 50 episodes.\n",
        "        \"\"\"\n",
        "        self.num_episodes_to_store = num_episodes_to_store\n",
        "        self.episode_return_buffer = []\n",
        "        self.current_episode_return = 0\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.current_episode_return += transition.reward\n",
        "\n",
        "        if transition.done: # If the episode is done\n",
        "            # Add episode return to buffer\n",
        "            self.episode_return_buffer.append(self.current_episode_return)\n",
        "\n",
        "            # Reset episode return\n",
        "            self.current_episode_return = 0\n",
        "\n",
        "\n",
        "    def is_ready(self):\n",
        "        return len(self.episode_return_buffer) == self.num_episodes_to_store\n",
        "\n",
        "    def sample(self):\n",
        "        average_episode_return = np.mean(self.episode_return_buffer)\n",
        "\n",
        "        # Clear episode return buffer\n",
        "        self.episode_return_buffer = []\n",
        "\n",
        "        return average_episode_return"
      ],
      "metadata": {
        "id": "pJIdj4-I6C6-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution exercise 4 {display-mode: \"form\"}\n",
        "\n",
        "def get_new_random_weights(random_key, old_weights,minval=-2.0,maxval=2.0):\n",
        "    new_weights_shape = old_weights.shape\n",
        "    new_weights_dtype = old_weights.dtype\n",
        "    # Sample new weights\n",
        "    new_weights = jax.random.uniform(random_key,new_weights_shape,new_weights_dtype,minval=minval,\n",
        "                      maxval=maxval)\n",
        "    return new_weights"
      ],
      "metadata": {
        "id": "hPkaGJLY6RNU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check exercise 4 (run me) {display-mode: \"form\"}\n",
        "\n",
        "def check_get_new_random_weights(get_new_random_weights):\n",
        "  old_weights = np.ones(obs_shape, \"float32\")\n",
        "  random_key = jax.random.PRNGKey(42)\n",
        "\n",
        "  # Case 1\n",
        "  new_weights = get_new_random_weights(random_key, old_weights, minval=-2.0, maxval=2.0)\n",
        "\n",
        "  if jnp.array_equal(new_weights, jnp.array([ 0.29657745,1.4265499, -1.7621555, -1.7505779 ])):\n",
        "    print(\"Function is correct!\")\n",
        "  else:\n",
        "    print(\"Something is wrong.\")\n",
        "\n",
        "try:\n",
        "  check_get_new_random_weights(get_new_random_weights)\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbW4dMDI6V8H",
        "outputId": "017a5390-bc0d-46bc-b85a-6af272c0648d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function is correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A NamedTuple to store the best average episode return so far\n",
        "RandomPolicyLearnState = collections.namedtuple(\n",
        "  \"RandomPolicyLearnState\",\n",
        "  [\"best_average_episode_return\"]\n",
        ")\n",
        "\n",
        "# Test\n",
        "initial_learn_state = RandomPolicyLearnState(best_average_episode_return=-float(\"inf\"))\n",
        "print(\"Initial best average episode return:\", initial_learn_state.best_average_episode_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8y4JmW6YlL",
        "outputId": "36b98c0e-e4da-4432-f862-67579076d047"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial best average episode return: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution exercise 5 {display-mode: \"form\"}\n",
        "\n",
        "def random_policy_search_learn(key, params, learn_state, memory):\n",
        "    best_params = params.best\n",
        "    current_params = params.current\n",
        "\n",
        "    current_average_episode_return = memory # the memory contains the average episode return\n",
        "    best_average_episode_return = learn_state.best_average_episode_return\n",
        "\n",
        "\n",
        "    # YOUR CODE\n",
        "\n",
        "    best_params = jax.lax.select(\n",
        "        current_average_episode_return > best_average_episode_return,\n",
        "        current_params,\n",
        "        best_params,\n",
        "    )\n",
        "\n",
        "    best_average_episode_return = jax.lax.select(\n",
        "        current_average_episode_return > best_average_episode_return,\n",
        "        current_average_episode_return,\n",
        "        best_average_episode_return\n",
        "    )\n",
        "\n",
        "    # END YOUR CODE\n",
        "\n",
        "    # Generate new random parameters\n",
        "    new_params = get_new_random_weights(key, current_params)\n",
        "\n",
        "    # Bundle weights in RandomPolicySearchParams NamedTuple\n",
        "    params = RandomPolicySearchParams(current=new_params, best=best_params)\n",
        "\n",
        "    # Update learn_state\n",
        "    learn_state = RandomPolicyLearnState(best_average_episode_return)\n",
        "\n",
        "    return params, learn_state"
      ],
      "metadata": {
        "id": "uwU24YFn7QgI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check exercise 5 {display-mode: \"form\"}\n",
        "\n",
        "params = RandomPolicySearchParams(np.ones(obs_shape, \"float32\"), np.ones(obs_shape, \"float32\") * -1)\n",
        "learn_state = RandomPolicyLearnState(10)\n",
        "memory = 11\n",
        "key = jax.random.PRNGKey(42)\n",
        "\n",
        "try:\n",
        "  new_params, new_learn_state = random_policy_search_learn(key, params, learn_state, memory)\n",
        "\n",
        "  if not jnp.array_equal(new_params.current, jnp.array([ 0.29657745,  1.4265499 , -1.7621555 , -1.7505779 ])):\n",
        "    print(\"Your function is incorrect.\")\n",
        "\n",
        "  elif not jnp.array_equal(new_params.best, jnp.array([1., 1., 1., 1.])):\n",
        "    print(\"Your function is incorrect.\")\n",
        "\n",
        "  elif new_learn_state.best_average_episode_return != 11:\n",
        "    print(\"Your function is incorrect.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Your function looks correct.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iChoNiLL7KKf",
        "outputId": "ec795a64-1a58-4464-dbd6-479efadfc2bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your function looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JIT the learn and choose action functions\n",
        "random_policy_search_learn_jit = jax.jit(random_policy_search_learn)\n",
        "random_policy_search_choose_action_jit = jax.jit(random_policy_search_choose_action)\n",
        "\n",
        "# Initialise the parameters\n",
        "initial_weights = np.ones(obs_shape, \"float32\")\n",
        "initial_params = RandomPolicySearchParams(initial_weights, initial_weights)\n",
        "\n",
        "# Initialise the learn state\n",
        "initial_learn_state = RandomPolicyLearnState(best_average_episode_return=-float(\"inf\"))\n",
        "\n",
        "# Initialise memory\n",
        "memory = AverageEpisodeReturnBuffer(num_episodes_to_store=50)\n",
        "\n",
        "# Run the training loop\n",
        "print(\"Starting training. This may take up to 5 minutes to complete.\")\n",
        "chex.clear_trace_counter()\n",
        "episode_return, evaluator_episode_returns = run_training_loop(\n",
        "                                        env_name,\n",
        "                                        initial_params,\n",
        "                                        random_policy_search_choose_action_jit,\n",
        "                                        None, # no actor state\n",
        "                                        random_policy_search_learn_jit,\n",
        "                                        initial_learn_state,\n",
        "                                        memory,\n",
        "                                        num_episodes=1001,\n",
        "                                        video_subdir=\"rps\"\n",
        "                                    )\n",
        "\n",
        "# Plot graph of evaluator episode returns\n",
        "plt.plot(np.linspace(0, 1000, len(evaluator_episode_returns)), evaluator_episode_returns)\n",
        "plt.title(\"Random Policy Search\")\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Episode Return\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "lf9SbjGk7fNS",
        "outputId": "0a33857a-a062-4b76-a799-eb9821ed9b80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training. This may take up to 5 minutes to complete.\n",
            "Episode: 0\tEpisode Return: 80.0\tAverage Episode Return: 80.0\tEvaluator Episode Return: 131.5\n",
            "Episode: 100\tEpisode Return: 38.0\tAverage Episode Return: 10.55\tEvaluator Episode Return: 130.75\n",
            "Episode: 200\tEpisode Return: 9.0\tAverage Episode Return: 9.75\tEvaluator Episode Return: 138.0\n",
            "Episode: 300\tEpisode Return: 186.0\tAverage Episode Return: 17.9\tEvaluator Episode Return: 121.0\n",
            "Episode: 400\tEpisode Return: 9.0\tAverage Episode Return: 120.25\tEvaluator Episode Return: 150.625\n",
            "Episode: 500\tEpisode Return: 64.0\tAverage Episode Return: 11.9\tEvaluator Episode Return: 128.0\n",
            "Episode: 600\tEpisode Return: 126.0\tAverage Episode Return: 15.25\tEvaluator Episode Return: 137.375\n",
            "Episode: 700\tEpisode Return: 200.0\tAverage Episode Return: 44.15\tEvaluator Episode Return: 154.0\n",
            "Episode: 800\tEpisode Return: 200.0\tAverage Episode Return: 18.5\tEvaluator Episode Return: 128.0\n",
            "Episode: 900\tEpisode Return: 37.0\tAverage Episode Return: 10.75\tEvaluator Episode Return: 188.375\n",
            "Episode: 1000\tEpisode Return: 9.0\tAverage Episode Return: 101.9\tEvaluator Episode Return: 169.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualise Policy {display-mode: \"form\"}\n",
        "#@markdown Choose an episode number that is a multiple of 100 and less than or equal to 2000, and **run** this cell.\n",
        "episode_number = 0 #@param {type:\"number\"}\n",
        "\n",
        "assert (episode_number % 100) == 0, \"Episode number must be a multiple of 100 since we only record every 100th episode.\"\n",
        "assert episode_number < 1001, \"Episode number must be less than or equal to 2000\"\n",
        "\n",
        "eval_episode_number = int(episode_number / 100 * 8)\n",
        "video_path = f\"./video/rps/eval/rl-video-episode-{eval_episode_number}.mp4\"\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "sGmglJT37nw-",
        "outputId": "56a23c28-e198-4b88-a28b-fd40152044da"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Policy Gradients (PG)**"
      ],
      "metadata": {
        "id": "IYVjjvO99CQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REINFORCE**"
      ],
      "metadata": {
        "id": "HQYuZMr_9GGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution exercise 6 {display-mode: \"form\"}\n",
        "\n",
        "def compute_weighted_log_prob(action_prob, episode_return):\n",
        "\n",
        "    # YOUR CODE\n",
        "\n",
        "    log_prob = jax.numpy.log(action_prob)\n",
        "\n",
        "    weighted_log_prob = log_prob * episode_return\n",
        "\n",
        "    # END YOUR CODE\n",
        "\n",
        "    return weighted_log_prob"
      ],
      "metadata": {
        "id": "wW37sZNR89LL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check exercise 6 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  action_prob = 0.8\n",
        "  episode_return = 100\n",
        "  result = compute_weighted_log_prob(action_prob, episode_return)\n",
        "  if result != -22.314354:\n",
        "    print(\"Your implementation looks incorrect.\")\n",
        "  else:\n",
        "    print(\"Looks correct.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HNjSj8r9LQq",
        "outputId": "4823d045-ce26-4c51-b4be-6dbb6e7a2df1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rewards-to-go**"
      ],
      "metadata": {
        "id": "-ceSCgl59WAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution exercise 7 {display-mode: \"form\"}\n",
        "\n",
        "def compute_rewards_to_go(rewards):\n",
        "    rewards_to_go = []\n",
        "    for i in range(len(rewards)):\n",
        "        r2g = 0\n",
        "        for j in range(i, len(rewards)):\n",
        "            r2g += rewards[j]\n",
        "        rewards_to_go.append(r2g)\n",
        "    return rewards_to_go"
      ],
      "metadata": {
        "id": "9a0JAAT79Nmm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Check exercise 7 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = compute_rewards_to_go([1,2,3,4])\n",
        "\n",
        "  if result != [10, 9, 7, 4]:\n",
        "    print(\"There is a problem with your implementation.\")\n",
        "  else:\n",
        "    print(\"Looks correct.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlctvpKJ9a4D",
        "outputId": "f39d8688-20be-4eea-ec99-91eef465bffd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution exercise 7 {display-mode: \"form\"}\n",
        "\n",
        "def compute_rewards_to_go(rewards):\n",
        "    rewards_to_go = []\n",
        "    for i in range(len(rewards)):\n",
        "        r2g = 0\n",
        "        for j in range(i, len(rewards)):\n",
        "            r2g += rewards[j]\n",
        "        rewards_to_go.append(r2g)\n",
        "    return rewards_to_go"
      ],
      "metadata": {
        "id": "gZ7u6eIi9eBm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check exercise 7 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = compute_rewards_to_go([1,2,3,4])\n",
        "\n",
        "  if result != [10, 9, 7, 4]:\n",
        "    print(\"There is a problem with your implementation.\")\n",
        "  else:\n",
        "    print(\"Looks correct.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psl9YKQN9iI9",
        "outputId": "cec3c988-9e0e-461a-9b0d-2645ba0031bd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REINFORCE memory**"
      ],
      "metadata": {
        "id": "_PSpLgAQ9w-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Memory implementation (run me) {display-mode: \"form\"}\n",
        "\n",
        "# NamedTuple to store memory\n",
        "EpisodeRewardsToGoMemory = collections.namedtuple(\"EpisodeRewardsToGoMemory\", [\"obs\", \"action\", \"reward_to_go\"])\n",
        "\n",
        "class EpisodeRewardsToGoBuffer:\n",
        "\n",
        "    def __init__(self, num_transitions_to_store=512, batch_size=256):\n",
        "        self.batch_size = batch_size\n",
        "        self.memory_buffer = collections.deque(maxlen=num_transitions_to_store)\n",
        "        self.current_episode_transition_buffer = []\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.current_episode_transition_buffer.append(transition)\n",
        "\n",
        "        if transition.done:\n",
        "\n",
        "            episode_rewards = []\n",
        "            for t in self.current_episode_transition_buffer:\n",
        "                episode_rewards.append(t.reward)\n",
        "\n",
        "            r2g = compute_rewards_to_go(episode_rewards)\n",
        "\n",
        "            for i, t in enumerate(self.current_episode_transition_buffer):\n",
        "                memory = EpisodeRewardsToGoMemory(t.obs, t.action, r2g[i])\n",
        "                self.memory_buffer.append(memory)\n",
        "\n",
        "            # Reset episode buffer\n",
        "            self.current_episode_transition_buffer = []\n",
        "\n",
        "\n",
        "    def is_ready(self):\n",
        "        return len(self.memory_buffer) >= self.batch_size\n",
        "\n",
        "    def sample(self):\n",
        "        random_memory_sample = random.sample(self.memory_buffer, self.batch_size)\n",
        "\n",
        "        obs_batch, action_batch, reward_to_go_batch = zip(*random_memory_sample)\n",
        "\n",
        "        return EpisodeRewardsToGoMemory(\n",
        "            np.stack(obs_batch).astype(\"float32\"),\n",
        "            np.asarray(action_batch).astype(\"int32\"),\n",
        "            np.asarray(reward_to_go_batch).astype(\"int32\")\n",
        "        )\n",
        "\n",
        "\n",
        "# Instantiate Memory\n",
        "REINFORCE_memory = EpisodeRewardsToGoBuffer(num_transitions_to_store=512, batch_size=256)"
      ],
      "metadata": {
        "id": "EmQsDMn49tE6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Policy neural network**"
      ],
      "metadata": {
        "id": "MCPeyDT094LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_policy_network(num_actions: int, layers=[20, 20]) -> hk.Transformed:\n",
        "  \"\"\"Factory for a simple MLP network for the policy.\"\"\"\n",
        "\n",
        "  def policy_network(obs):\n",
        "    network = hk.Sequential(\n",
        "        [\n",
        "            hk.Flatten(),\n",
        "            hk.nets.MLP(layers + [num_actions])\n",
        "        ]\n",
        "    )\n",
        "    return network(obs)\n",
        "\n",
        "  return hk.without_apply_rng(hk.transform(policy_network))"
      ],
      "metadata": {
        "id": "WIt0-LNC90_M"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "POLICY_NETWORK = make_policy_network(num_actions=num_actions, layers=[20,20])\n",
        "random_key = jax.random.PRNGKey(42) # random key\n",
        "dummy_obs = np.ones(obs_shape, \"float32\")\n",
        "\n",
        "# Initialise parameters\n",
        "REINFORCE_params = POLICY_NETWORK.init(random_key, dummy_obs)\n",
        "print(\"Initial params:\", REINFORCE_params.keys())\n",
        "\n",
        "# Pass input through the network\n",
        "output = POLICY_NETWORK.apply(REINFORCE_params, dummy_obs)\n",
        "print(\"Policy network output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i-bCsSr97uq",
        "outputId": "3d4f26fd-dd53-451d-c781-f3c79d39f604"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial params: dict_keys(['mlp/~/linear_0', 'mlp/~/linear_1', 'mlp/~/linear_2'])\n",
            "Policy network output: [ 0.91155875 -0.39617383]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REINFORCE choose action function**"
      ],
      "metadata": {
        "id": "6El4dHhW-BPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution exercise 8 {display-mode: \"form\"}\n",
        "\n",
        "def sample_action(random_key, logits):\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    action = jax.random.categorical(random_key, logits)\n",
        "\n",
        "    # END YOUR code\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "SQZ1kt6w9-4c"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check exercise 8 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  random_key = jax.random.PRNGKey(42) # random key\n",
        "  action = sample_action(random_key, np.array([1,2], \"float32\"))\n",
        "  if action != 1:\n",
        "    print(\"Your function is incorrect.\")\n",
        "  else:\n",
        "    print(\"Seems correct.\")\n",
        "except Exception as e:\n",
        "    print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMZG1C6C-FqI",
        "outputId": "bf495550-c32c-4230-d1ae-222ffc4ca083"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def REINFORCE_choose_action(key, params, actor_state, obs, evaluation=False):\n",
        "  obs = jnp.expand_dims(obs, axis=0) # add dummy batch dim before passing through network\n",
        "\n",
        "  # Pass obs through policy network to compute logits\n",
        "  logits = POLICY_NETWORK.apply(params, obs)\n",
        "  logits = logits[0] # remove batch dim\n",
        "\n",
        "  # Randomly sample action\n",
        "  sampled_action = sample_action(key, logits)\n",
        "\n",
        "  return sampled_action, actor_state"
      ],
      "metadata": {
        "id": "_id3lQtr-JTV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Policy gradient loss**"
      ],
      "metadata": {
        "id": "NqbtxRCJ-Q-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution exercise 9 {display-mode: \"form\"}\n",
        "\n",
        "def policy_gradient_loss(action, logits, reward_to_go):\n",
        "\n",
        "  # YOUR CODE\n",
        "\n",
        "  all_action_probs = jax.nn.softmax(logits) # convert logits into probs\n",
        "\n",
        "  action_prob = all_action_probs[action]\n",
        "\n",
        "  weighted_log_prob = compute_weighted_log_prob(action_prob, reward_to_go)\n",
        "\n",
        "  # END YOUR CODE\n",
        "\n",
        "  loss = - weighted_log_prob # negative because we want gradient `ascent`\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "5ojK1NgV-Op-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check exercise 9 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = policy_gradient_loss(1, np.array([1,2], \"float32\"), 10)\n",
        "  if result != 3.1326165:\n",
        "    print(\"Your implementation looks wrong.\")\n",
        "  else:\n",
        "    print(\"Looks correct.\")\n",
        "except Exception as e:\n",
        "  print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW_7BfLj-VQW",
        "outputId": "586b430d-cd68-46d1-9bfe-f7e8c441d4fd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your implementation looks wrong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batched_policy_gradient_loss(params, obs_batch, action_batch, reward_to_go_batch):\n",
        "    # Get logits by passing observation through network\n",
        "    logits_batch = POLICY_NETWORK.apply(params, obs_batch)\n",
        "\n",
        "    policy_gradient_loss_batch = jax.vmap(policy_gradient_loss)(action_batch, logits_batch, reward_to_go_batch) # add batch\n",
        "\n",
        "    # Compute mean loss over batch\n",
        "    mean_policy_gradient_loss = jnp.mean(policy_gradient_loss_batch)\n",
        "\n",
        "    return mean_policy_gradient_loss\n",
        "\n",
        "# TEST\n",
        "obs_batch = np.ones((3, *obs_shape), \"float32\")\n",
        "actions_batch = np.array([1,0,0])\n",
        "rew2go_batch = np.array([2.3, 4.3, 2.1])\n",
        "\n",
        "loss = batched_policy_gradient_loss(REINFORCE_params, obs_batch, actions_batch, rew2go_batch)\n",
        "\n",
        "print(\"Policy gradient loss on batch:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUU3YfvB-ZGh",
        "outputId": "0d191fb8-0c9d-4b1b-f85e-b7f57e6de182"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy gradient loss on batch: 1.6967316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REINFORCE_OPTIMIZER = optax.adam(1e-3)\n",
        "\n",
        "# Initialise the optimiser\n",
        "REINFORCE_optim_state = REINFORCE_OPTIMIZER.init(REINFORCE_params)"
      ],
      "metadata": {
        "id": "ZqdWxUj2-1Sn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A NamedTuple to store the state of the optimiser\n",
        "REINFORCELearnState = collections.namedtuple(\"LearnerState\", [\"optim_state\"])\n",
        "\n",
        "\n",
        "def REINFORCE_learn(key, params, learner_state, memory):\n",
        "\n",
        "  # Get the policy gradient by using `jax.grad()` on `batched_policy_gradient_loss`\n",
        "  grad_loss = jax.grad(batched_policy_gradient_loss)(params, memory.obs, memory.action, memory.reward_to_go)\n",
        "\n",
        "  # Get param updates using gradient and optimizer\n",
        "  updates, new_optim_state = REINFORCE_OPTIMIZER.update(grad_loss, learner_state.optim_state)\n",
        "\n",
        "  # Apply updates to params\n",
        "  params = optax.apply_updates(params, updates)\n",
        "\n",
        "  return params, REINFORCELearnState(new_optim_state) # update learner state"
      ],
      "metadata": {
        "id": "KtDR_8s3-5LX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REINFORCE training loop**"
      ],
      "metadata": {
        "id": "Z3ZKhmNp--Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JIT the choose_action and learn functions for more speed\n",
        "REINFORCE_learn_jit = jax.jit(REINFORCE_learn)\n",
        "REINFORCE_choose_action_jit = jax.jit(REINFORCE_choose_action)\n",
        "\n",
        "# Initial learn state\n",
        "REINFORCE_learn_state = REINFORCELearnState(REINFORCE_optim_state)\n",
        "\n",
        "# Run training loop\n",
        "print(\"Starting training. This may take up to 10 minutes to complete.\")\n",
        "episode_returns, evaluator_returns = run_training_loop(\n",
        "                                        env_name,\n",
        "                                        REINFORCE_params,\n",
        "                                        REINFORCE_choose_action_jit,\n",
        "                                        None, # action state not used\n",
        "                                        REINFORCE_learn_jit,\n",
        "                                        REINFORCE_learn_state,\n",
        "                                        REINFORCE_memory,\n",
        "                                        num_episodes=10_001,\n",
        "                                        learn_steps_per_episode=2,\n",
        "                                        video_subdir=\"reinforce\"\n",
        "                                      )\n",
        "\n",
        "# Plot the episode returns\n",
        "plt.plot(episode_returns)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Episode Return\")\n",
        "plt.title(\"REINFORCE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnq-GUcD-7wG",
        "outputId": "5362301a-9fe1-4394-fd4a-12c056b5e2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training. This may take up to 10 minutes to complete.\n",
            "Episode: 0\tEpisode Return: 12.0\tAverage Episode Return: 12.0\tEvaluator Episode Return: 18.625\n",
            "Episode: 100\tEpisode Return: 48.0\tAverage Episode Return: 86.2\tEvaluator Episode Return: 103.375\n",
            "Episode: 200\tEpisode Return: 182.0\tAverage Episode Return: 140.85\tEvaluator Episode Return: 147.25\n",
            "Episode: 300\tEpisode Return: 180.0\tAverage Episode Return: 180.05\tEvaluator Episode Return: 199.625\n",
            "Episode: 400\tEpisode Return: 200.0\tAverage Episode Return: 151.8\tEvaluator Episode Return: 159.0\n",
            "Episode: 500\tEpisode Return: 200.0\tAverage Episode Return: 194.25\tEvaluator Episode Return: 195.375\n",
            "Episode: 600\tEpisode Return: 200.0\tAverage Episode Return: 195.8\tEvaluator Episode Return: 185.125\n",
            "Episode: 700\tEpisode Return: 139.0\tAverage Episode Return: 196.95\tEvaluator Episode Return: 192.5\n",
            "Episode: 800\tEpisode Return: 200.0\tAverage Episode Return: 200.0\tEvaluator Episode Return: 200.0\n",
            "Episode: 900\tEpisode Return: 177.0\tAverage Episode Return: 191.2\tEvaluator Episode Return: 192.625\n",
            "Episode: 1000\tEpisode Return: 164.0\tAverage Episode Return: 162.75\tEvaluator Episode Return: 137.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise Policy {display-mode: \"form\"}\n",
        "#Choose an episode number that is a multiple of 100 and less than or equal to 1000, and **run this cell**.\n",
        "\n",
        "episode_number = 100 #@param {type:\"number\"}\n",
        "\n",
        "assert (episode_number % 100) == 0, \"Episode number must be a multiple of 100 since we only record every 100th episode.\"\n",
        "assert episode_number < 1001, \"Episode number must be less than or equal to 1000\"\n",
        "\n",
        "eval_episode_number = int(episode_number / 100 * 8)\n",
        "video_path = f\"./video/reinforce/eval/rl-video-episode-{eval_episode_number}.mp4\"\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "GS6kI2wc_CdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q-Learning**\n",
        "\n",
        "Another common aproach to finding an optimal policy in an environment using RL is via Q-learning."
      ],
      "metadata": {
        "id": "Ygy8137z_QUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **State-Action Value function**"
      ],
      "metadata": {
        "id": "M5HHI3c6_W20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Greedy action selection**"
      ],
      "metadata": {
        "id": "gfcZVLDb_ak0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution exercise 10 {display-mode: \"form\"}\n",
        "\n",
        "def select_greedy_action(q_values):\n",
        "\n",
        "  # YOUR CODE\n",
        "  action = jnp.argmax(q_values)\n",
        "  # END YOUR CODE\n",
        "\n",
        "  return action"
      ],
      "metadata": {
        "id": "ntEAFOZU_UEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Check exercise 10 (run me) {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  q_values = jnp.array([1,1,3,4])\n",
        "  action = select_greedy_action(q_values)\n",
        "\n",
        "  if action != 3:\n",
        "    print(\"Incorrect answer, your greedy action selector looks wrong\")\n",
        "  else:\n",
        "    print(\"Looks good.\")\n",
        "except Exception as e:\n",
        "  print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "id": "PK7yAOxH_ibz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q-Network**"
      ],
      "metadata": {
        "id": "KUof0oo0_pw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network(num_actions: int, layers=[20, 20]) -> hk.Transformed:\n",
        "  \"\"\"Factory for a simple MLP network for approximating Q-values.\"\"\"\n",
        "\n",
        "  def q_network(obs):\n",
        "    network = hk.Sequential(\n",
        "        [hk.Flatten(),\n",
        "         hk.nets.MLP(layers + [num_actions])])\n",
        "    return network(obs)\n",
        "\n",
        "  return hk.without_apply_rng(hk.transform(q_network))"
      ],
      "metadata": {
        "id": "q1Rhh2WN_m9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise Q-network\n",
        "Q_NETWORK = build_network(num_actions=num_actions, layers=[20, 20]) # two actions\n",
        "\n",
        "dummy_obs = jnp.zeros((1,*obs_shape), jnp.float32) # a dummy observation like the one in CartPole\n",
        "\n",
        "random_key = jax.random.PRNGKey(42) # random key\n",
        "Q_NETWORK_PARAMS = Q_NETWORK.init(random_key, dummy_obs) # Get initial params\n",
        "\n",
        "print(\"Q-Learning params:\", Q_NETWORK_PARAMS.keys())"
      ],
      "metadata": {
        "id": "d94JXirI_tD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Bellman Equations**"
      ],
      "metadata": {
        "id": "l-KzCzd__xdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Bellman Backup**"
      ],
      "metadata": {
        "id": "2k6RM1SX_1HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution exercise 11 {display-mode: \"form\"}\n",
        "def compute_squared_error(pred, target):\n",
        "\n",
        "  # YOUR CODE\n",
        "  squared_error = jax.numpy.square(pred - target)\n",
        "  # END YOUR CODE\n",
        "  return squared_error"
      ],
      "metadata": {
        "id": "K2Hj5gdW_vt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check exercise 11 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = compute_squared_error(1, 4)\n",
        "\n",
        "  if result != 9:\n",
        "    print(\"Your implementation looks wrong.\")\n",
        "  else:\n",
        "    print(\"Looks good.\")\n",
        "except Exception as e:\n",
        "  print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "id": "tbB4kguA_7Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution exercise 12 {display-mode: \"form\"}\n",
        "\n",
        "# Bellman target\n",
        "def compute_bellman_target(reward, done, next_q_values):\n",
        "    \"\"\"A function to compute the bellman target.\n",
        "\n",
        "    Args:\n",
        "        reward: a scalar reward.\n",
        "        done: a scalar of value either 1.0 or 0.0, indicating if the transition is a terminal one.\n",
        "        next_q_values: a vector of q_values for the next state. One for each action.\n",
        "    Returns:\n",
        "        A scalar equal to the bellman target.\n",
        "\n",
        "    \"\"\"\n",
        "    # YOUR CODE\n",
        "    bellman_target = reward + (1.0 - done) * jax.numpy.max(next_q_values)\n",
        "    # END YOUR CODE\n",
        "\n",
        "    return bellman_target"
      ],
      "metadata": {
        "id": "aSn41PtL_9SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check exercise 12 {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  # not done\n",
        "  result1 = compute_bellman_target(1, 0.0, np.array([3,2], \"float32\"))\n",
        "\n",
        "  # done\n",
        "  result2 = compute_bellman_target(1, 1.0, np.array([3,2], \"float32\"))\n",
        "\n",
        "  if result1 != 4 or result2 != 1:\n",
        "    print(\"Your implementation looks wrong.\")\n",
        "  else:\n",
        "    print(\"Looks good.\")\n",
        "except Exception as e:\n",
        "  print(\"An Error Occured: {}\".format(e))"
      ],
      "metadata": {
        "id": "e86o0WVeAFx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3vT8WdWAJVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}